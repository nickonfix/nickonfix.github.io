<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="StciUgNJIeNMcpp3ckOUsfpzngKqEZpjl4wllWi8r-4"> <meta name="msvalidate.01" content=""> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Nikhil Singh </title> <meta name="author" content="Nikhil Singh"> <meta name="description" content="Nikhil's personal website. "> <link rel="stylesheet" href="/assets/css/main.css?v=20"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700%7CRoboto+Slab:100,300,400,500,700%7CMaterial+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9E%B0&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://nickonfix.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%61%69%78%6E%69%63%6B@%69%63%6C%6F%75%64.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://github.com/nickonfix" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://leetcode.com/u/DebugNick/" target="_blank" title="LeetCode" rel="external nofollow noopener"><i class="si si-leetcode"></i></a> <a href="https://www.linkedin.com/in/heyvisitor" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://twitter.com/CmonNicktf" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item"> <a target="_blank" class="nav-link" href="/assets/pdf/nick.pdf">CV</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Experience </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">Search<i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Nikhil</span> Singh </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/no-smile-480.webp 480w,/assets/img/no-smile-800.webp 800w,/assets/img/no-smile-1400.webp 1400w," type="image/webp" sizes="(min-width: 800px) 231.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/no-smile.png?85e5e20bee84f5016f8efa7f90da3063" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="no-smile.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p>Hi, I’m a Research Intern at <a href="https://www.linkedin.com/company/atheropoint" target="_blank" class="web-link" rel="external nofollow noopener">AtheroPoint</a>, where I work on transformer-based architectures, embedded attention mechanisms, and data-efficient <a href="https://en.wikipedia.org/wiki/Deep_learning" target="_blank" class="web-link" rel="external nofollow noopener">deep learning</a> models for large-scale biomedical and imaging datasets. My research focuses on sequence modeling, <a href="https://en.wikipedia.org/wiki/Representation_learning" target="_blank" class="web-link" rel="external nofollow noopener">representation learning</a>, and attention-driven transformer variants methods that naturally extend to modern <a href="https://en.wikipedia.org/wiki/Natural_language_processing" target="_blank" class="web-link" rel="external nofollow noopener">NLP</a> systems.</p> <p>Although my recent work is rooted in biomedical AI, the underlying techniques I use transformers, self-supervised learning, and attention mechanisms are fundamentally domain general. These are the same principles that drive today’s NLP systems, motivating my transition toward language modeling, multimodal understanding, and efficient transformer design.</p> <p>My current research at AtheroPoint is supervised by <a href="https://scholar.google.com/citations?user=AKJK7UQAAAAJ&amp;hl=en" target="_blank" class="web-link" rel="external nofollow noopener">Dr. Jasjit Singh Suri</a> and <a href="https://scholar.google.co.in/citations?user=cppq2DcAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" class="web-link" rel="external nofollow noopener">Prof. Luca Saba</a>, whose mentorship has strengthened my foundations in deep learning architecture design, attention models, and model optimization.</p> <p>I completed my Bachelor of Technology at <a href="https://bvcoend.ac.in/" target="_blank" rel="noopener noreferrer" class="web-link"> Bharati Vidyapeeth College of Engineering, New Delhi </a>. where I worked under the mentorship of <a href="https://scholar.google.com/citations?user=4IC-Sw8AAAAJ&amp;hl=en&amp;oi=ao" target="_blank" class="web-link" rel="external nofollow noopener">Dr. Arun K. Dubey</a> and <a href="https://scholar.google.co.in/citations?hl=en&amp;user=mFlMAqcAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" target="_blank" class="web-link" rel="external nofollow noopener">Dr. Rubbena Vohra</a>. Their early guidance introduced me to deep learning, transformers, and representation learning, shaping my interest in model generalization and sequence understanding.</p> <p>I am currently preparing for Fall 2026 MS/PhD applications, with broad research interests in transformers, NLP, self-supervised learning, sequence modeling, and scalable model efficiency.</p> <p>Outside research, I practice <a href="https://en.wikipedia.org/wiki/Competitive_programming" target="_blank" class="web-link" rel="external nofollow noopener">competitive programming</a> to strengthen my <a href="https://en.wikipedia.org/wiki/Algorithm" target="_blank" class="web-link" rel="external nofollow noopener">algorithmic reasoning</a> and <a href="https://en.wikipedia.org/wiki/Computational_efficiency" target="_blank" class="web-link" rel="external nofollow noopener">computational efficiency</a>, which supports my work on optimizing deep learning architectures.</p> </div> <h2> <a href="/news/" style="color: inherit">Latest Updates</a> </h2> <div class="News"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Nov 10, 2025</th> <td> Applying to PhD and Master’s Programs </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 01, 2025</th> <td> Joined as a Research Intern at Atheropoint LLC </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 01, 2025</th> <td> Graduated from Bharati Vidyapeeth College of Engineering! </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">Publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Measurment</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/meas-480.webp 480w,/assets/img/publication_preview/meas-800.webp 800w,/assets/img/publication_preview/meas-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/meas.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="meas.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="singh2025meas" class="col-sm-8"> <div class="title">Attention/Transformer-based Artificial Intelligence Models for Carotid Segmentation and Intima Media Thickness/Plaque Area Measurements in Japanese Ultrasound Scans</div> <div class="author"> <em>Nikhil Singh<sup>*</sup></em>, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Jasjit Singh Suri, Others' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Measurement Journal (Elesvier) (Q1, IF = 5.6) (In Revison November 2025)</em>, Jul 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.sciencedirect.com/journal/measurement" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/MEAS.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Background and Motivation: Accurate plaque segmentation and measurement in carotid ultrasound scans is essential for effective diagnosis and cardiovascular disease (CVD) risk stratification. The latest techniques based on solo single stage deep learning UNet (M1:SS- UNet) leads to inconsistency in low contrast scans. We hypothesize that variants of UNet such as transformers can be more powerful paradigms. Method: Design and develop novel single-stage UNet-based transformer (M6:SSwAttSkip- XmerBot-UNet) for the far wall segmentation and intima-media thickness/plaque area measurements in Japanese diabetic cohort. We use augmented data and cross-validation protocol for performance evaluation and generalization. Performance evaluation includes 16 novel metrics, namely model complexity, model size, training efficiency, performance to model size ratio, performance to complexity, and training time. We benchmarked our novel transformer system against five models utilizing single and double stage attention-based configurations namely M1:SS-UNet, single-stage with attention-UNet (M2:SSwAttSkip- UNet), double-stage with attention-UNet (M3:DSwAttSkip-UNet), double-stage with attention in decoder UNet (M4:DSwAttDeco-UNet) and single stage with transformer in the bottle neck layer (M5:SSTransBot-UNet) Results: The results showed that M6:SSwAttSkip-XmerBot-UNet achieved a perfect score of 100%, while M4:DSwAttDeco-UNet followed closely by 93.93%. Both models consistently outperformed M1:SS-UNet, M2:SSwAttSkip-UNet, M3:DSwAttSkip-UNet and M5: SSTransBot-UNet across all the 16 metrics. The final ranking of the UNet models were: SSwAttSkip-XmerBot-UNet&gt;DSwAttDeco-UNet&gt;SS-UNet&gt;SSTransBot-UNet&gt; SSwAttSkip-UNet&gt;DSwAttSkip-UNet. M6:SSwAttSkip-XmerBot-UNet demonstrates comparable effectiveness with greater efficiency, making it a strong alternative. Conclusions: We conclude that transformer-based models like M6:SSwAttSkip-XmerBot- UNet provide highly accurate, reliable, and automated technique that segments and measures the risk of CVD.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">KBS</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Kbs-480.webp 480w,/assets/img/publication_preview/Kbs-800.webp 800w,/assets/img/publication_preview/Kbs-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/Kbs.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Kbs.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="singh2025kbs" class="col-sm-8"> <div class="title">Plaque Burden and Carotid Intima-Media Thickness Measurements in Ultrasound Scans: Are Transformer Tuners a Must for UNet Architectures?</div> <div class="author"> <em>Nikhil Singh<sup>*</sup></em>, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Jasjit Singh Suri, Others' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Knowledge-based Systems (Elesvier) (Q1, IF = 7.6) (Under Review November 2025)</em>, Oct 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.sciencedirect.com/journal/knowledge-based-systems" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/KBS.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Background and Motivation: UNet-based Deep Learning systems have dominated in the field of medical imaging for segmentation of organs; however, it is not accurate, validated, or generalized. Transformers or attention, on the other hand, provide solutions that are sophisticated but use heavy-duty computations and take a long time to converge. This study introduces a two-stage segmentation solution that combines transformers as tuners to the base UNet, resulting in a highly accurate and generalizable solution. Method: Three sets of base UNets were designed, namely, B1:UNet, B2: UNet++, and B3:UNet+++, and four sets of tuners were designed, namely: T1:Transformer-augmented UNet, T2:Attention-guided UNet, T3:Swin Transformer-based UNet, and T4:Pyramid-based network, leading to 12 fusion systems that combine three base UNets and four Tuners, namely: B1+T1, B1+T2, B1+T3, B1+T4; B2+T1, B2+T2, B2+T3, B2+T4; B3+T1, B3+T2, B3+T3, B3+T4. A comparison is made on 13 important metrics, including model size, complexity, training time, inference speed, and accuracy-to-parameter efficiency. Results show that B1+T4, which achieved the highest normalisation score of 100%, was the best-performing system. Results: Findings indicate that the two-stage segmentation model is more effective and reliable than the single-stage UNet architecture. The combination of single UNet backbones and transformers/attention mechanisms then creates a structure-sensitive and extremely nuanced pipeline. Altogether, the proposed hybrid framework is scalable, high-throughput, and fits properly into the real-life clinical practice where the accuracy and stability of segmentation vital importance. Conclusions: We conclude that Hybrid transformer-based models like B1+T4 provide highly accurate, reliable, and automated techniques that segments and measure the risk of CVD.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">BSPC</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/bspc-480.webp 480w,/assets/img/publication_preview/bspc-800.webp 800w,/assets/img/publication_preview/bspc-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/bspc.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="bspc.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="sinha2025bspc" class="col-sm-8"> <div class="title">A Comparative study of the latest Artificial intelligence-based Models for Plaque Measurement in a Carotid Ultrasound-based Japanese Cohort</div> <div class="author"> <em>Nikhil Singh<sup>*</sup></em>, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Jasjit Singh Suri, Others' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Biomedical Signal Processing and Control (Elesvier) (Q1, IF = 4.9) (Under Review July 2025)</em>, Mar 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.sciencedirect.com/journal/biomedical-signal-processing-and-control" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/BSPC.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Background and Motivation: Accurate plaque measurement in carotid ultrasound images is essential for effective diagnosis and CVD risk stratification. Traditional methods for plaque assessment rely on manual segmentation and rule-based approaches, leading to inconsistent results and observer variability. Although deep learning (DL) models have increased segmentation accuracy, they face challenges in dealing with complex plaque structures as well as low contrast ultrasound images. This study aims to compare state-of-the-art AI-driven models for carotid plaque measurement, evaluating their efficiency, robustness, and clinical applicability in a Japanese cohort. Method: This study evaluates three deep learning models, i.e., (i) conventional neural networks(cNonAtt-dsCNN), (ii) attention-enhanced U-Net(cAtt-ssUNet),(iii) a two-stage attention-based method(cAtt-dsUNet) and compares against commercial AtheroEdge™ 2.0(AE2.0) from AtheroPoint, CA, USA-an automated method. All three DL models were trained on the same Japanese data with identical hyperparameters using the Adam optimizer, batch size 32, and a learning rate of 0.001 on an NVIDIA GPU cluster. The metrics used were: (i) total plaque area, and carotid intima-media thickness (cIMT), giving the automated lumen-intima, and media-adventitia (LIMA) boundaries in the far wall carotid ultrasound scans. The performance of these models was assessed using (i) Dice similarity, (ii) Jaccard index on binary segmented walls, and (iii) polyline distance metric for measuring cIMT. Conclusions: cAtt-dsUNet outperformed traditional DL methods and is comparable to the commercial system AtheroEdge™.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">US Patent</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Patent-480.webp 480w,/assets/img/publication_preview/Patent-800.webp 800w,/assets/img/publication_preview/Patent-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/Patent.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Patent.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="patent2025singh" class="col-sm-8"> <div class="title">Two Stage Systems</div> <div class="author"> Nikhil Singh (Co-Inventor) </div> <div class="periodical"> <em>US Patent App, To be filed by</em>, Dec 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Will be available post patent filing.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%61%69%78%6E%69%63%6B@%69%63%6C%6F%75%64.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://github.com/nickonfix" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://leetcode.com/u/DebugNick/" target="_blank" title="LeetCode" rel="external nofollow noopener"><i class="si si-leetcode"></i></a> <a href="https://www.linkedin.com/in/heyvisitor" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://twitter.com/CmonNicktf" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <div class="contact-note">Ping me on X (Twitter) ! </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Nikhil Singh. Last updated: November 15, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script src="/assets/js/tooltips-setup.js?53023e960fbc64cccb90d32e9363de2b"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?70d799092f862ad98c7876aa47712e20"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-FKBC748YS4"></script> <script defer src="/assets/js/google-analytics-setup.js?12374742c4b1801ba82226e617af7e2d"></script> <script async src="https://rum.cronitor.io/script.js"></script> <script defer src="/assets/js/cronitor-analytics-setup.js?edde7e927b37b35ed2e06db320ee68e0"></script> <script defer src="https://api.pirsch.io/pa.js" id="pianjs" data-code=""></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?45fa3b82428dcfb97aea5fe46aa97eba"></script> </body> </html>